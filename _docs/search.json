[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "perceptnetfastai",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "perceptnetfastai",
    "section": "Install",
    "text": "Install\npip install perceptnetfastai"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "perceptnetfastai",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "00_Data/data_loading.html",
    "href": "00_Data/data_loading.html",
    "title": "Loading the data",
    "section": "",
    "text": "Another important thing to note is that each distorted image is named in a meaningful way: I(img_id)_(dist_id)_(dist_int).bmp, so we may use that information at our discretion. Leaving complicated filterings aside, we can start by loading all the images and connecting them.\nWe will start by loading the mos_with_names.txt file defining our DataBlock:\n\ndf = pd.read_csv(path_txt, header=None, sep=\" \", names=[\"MOS\", \"Dist\"])\ndf.head()\n\n\n\n\n\n  \n    \n      \n      MOS\n      Dist\n    \n  \n  \n    \n      0\n      5.9706\n      i01_01_1.bmp\n    \n    \n      1\n      5.4167\n      i01_01_2.bmp\n    \n    \n      2\n      4.5556\n      i01_01_3.bmp\n    \n    \n      3\n      4.3143\n      i01_01_4.bmp\n    \n    \n      4\n      6.1429\n      i01_02_1.bmp\n    \n  \n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nTurns out that the filenames in the .txt file are lowercase but the filenames of the images are uppercase. Because we can’t modify any of those to avoid breaking other’s people code, we have to uppercase the initial I of the image names in the loaded dataframe.\n\n\n\ndf['Dist'] = df.Dist.apply(fix_dist_name)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      MOS\n      Dist\n    \n  \n  \n    \n      0\n      5.9706\n      I01_01_1.bmp\n    \n    \n      1\n      5.4167\n      I01_01_2.bmp\n    \n    \n      2\n      4.5556\n      I01_01_3.bmp\n    \n    \n      3\n      4.3143\n      I01_01_4.bmp\n    \n    \n      4\n      6.1429\n      I01_02_1.bmp\n    \n  \n\n\n\n\nTo avoid unnecessary hustle, we can a column to our dataframe that points to the corresponding reference_image and we should be good to go. Keep in mind that, as we should be expecting this far in, reference images are all in uppercase format (extension included), so we’ll have to adjust consequently.\n\na = \"I01_01_1.bmp\"\nassert get_ref_name(a) == 'I01.BMP'\n\n\ndf['Ref'] = df.Dist.apply(get_ref_name)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      MOS\n      Dist\n      Ref\n    \n  \n  \n    \n      0\n      5.9706\n      I01_01_1.bmp\n      I01.BMP\n    \n    \n      1\n      5.4167\n      I01_01_2.bmp\n      I01.BMP\n    \n    \n      2\n      4.5556\n      I01_01_3.bmp\n      I01.BMP\n    \n    \n      3\n      4.3143\n      I01_01_4.bmp\n      I01.BMP\n    \n    \n      4\n      6.1429\n      I01_02_1.bmp\n      I01.BMP\n    \n  \n\n\n\n\nWe will be saving the generated .csv to skip this step further:\n\ndf.to_csv(\"../tid2008.csv\")\n\n\ndblock = DataBlock(blocks=(ImageBlock, ImageBlock, RegressionBlock),\n                   getters=[ColReader(2, pref=path_ref),\n                            ColReader(1, pref=path_dist),\n                            ColReader(0)],\n                   n_inp=2)\n\n\ndls = dblock.dataloaders(df, bs=4)\n\nWe have a kind of “complicated” data with two input images and one output, so we can’t use the base .show_batch() method right away. Instead, we can iterate over the DataLoader by hand to plot the data:\n\nfor img_ref, img_dist, mos in dls.train:\n    break\n\n\nfig, axes = plt.subplots(4,2, figsize=(4,6))\n\nfor i in range(len(axes)):\n    axes[i,0].imshow(img_ref[i].permute(1,2,0))\n    axes[i,0].set_title(\"Reference\")\n    axes[i,1].imshow(img_dist[i].permute(1,2,0))\n    axes[i,1].set_title(f\"Distorted (MOS={mos[i]:.2f})\")\n\nfor ax in axes.ravel(): ax.axis('off')\n\nplt.show()"
  },
  {
    "objectID": "01_Model/perceptnet.html",
    "href": "01_Model/perceptnet.html",
    "title": "Basic PerceptNet",
    "section": "",
    "text": "Custom non-linear layer performing a somewhat-normalization of the input images taking into account local neighborhoods.\n\n\n\n\n\n GDN (in_channels, out_channels, kernel_size=3, gamma_init=0.1,\n      alpha_init=2, epsilon_init=0.5, alpha_trainable=False,\n      epsilon_trainable=False, reparam_offset=3.814697265625e-06,\n      beta_min=1e-06, apply_independently=False,\n      kernel_initializer='identity', data_format='channels_first',\n      **kwargs)\n\nGDN custom layer.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nin_channels\n\n\nNumber of channels at input.\n\n\nout_channels\n\n\nNumber of channels at output.\n\n\nkernel_size\nint\n3\nKernel of the convolution.\n\n\ngamma_init\nfloat\n0.1\nGamma parameter.\n\n\nalpha_init\nint\n2\nInitial value of alpha.\n\n\nepsilon_init\nfloat\n0.5\nInitial value of epsilon.\n\n\nalpha_trainable\nbool\nFalse\nWether alpha is a trainable parameter.\n\n\nepsilon_trainable\nbool\nFalse\nWether epsilon is a trainable parameter.\n\n\nreparam_offset\nfloat\n3.814697265625e-06\nNumerical stability trick.\n\n\nbeta_min\nfloat\n1e-06\nMinimum value of beta.\n\n\napply_independently\nbool\nFalse\nWether to do grouped convolutions or not.\n\n\nkernel_initializer\nstr\nidentity\nInitialization of the convolution kernel.\n\n\ndata_format\nstr\nchannels_first\nFormat of the input data.\n\n\nkwargs\n\n\n\n\n\n\n\ngdn = GDN(in_channels=3, out_channels=3)\n\n\ninput_sample = torch.rand(size=(1,3,28,28))\noutput_sample = gdn(input_sample).detach()\n\nassert input_sample.shape == output_sample.shape\n\n[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n\n\n\nfig, axes = plt.subplots(1,2, figsize=(9,4))\naxes[0].imshow(input_sample.squeeze().permute(1,2,0))\naxes[1].imshow(output_sample.squeeze().permute(1,2,0))\nfor ax in axes: ax.axis(\"off\")\nplt.show()"
  },
  {
    "objectID": "01_Model/perceptnet.html#model",
    "href": "01_Model/perceptnet.html#model",
    "title": "Basic PerceptNet",
    "section": "Model",
    "text": "Model\n\nDefinition of the model.\n\n\n\nPerceptNet\n\n PerceptNet (in_channels)\n\nBasic PerceptNet architecture.\n\n\n\n\nDetails\n\n\n\n\nin_channels\nInput channels."
  },
  {
    "objectID": "01_Model/perceptnet.html#loss-function",
    "href": "01_Model/perceptnet.html#loss-function",
    "title": "Basic PerceptNet",
    "section": "Loss function",
    "text": "Loss function\n\nThe model is going to be trained to maximize the correlation between the distance in the transformed space and the MOS.\n\n\n\nloss_perceptnet_fn\n\n loss_perceptnet_fn (imgs, mos)\n\n\n\n\n\nDetails\n\n\n\n\nimgs\nTuple of (ref_imgs, dist_imgs) in the transformed space.\n\n\nmos\nReal Mean Opinion Score"
  },
  {
    "objectID": "01_Model/perceptnet.html#testing-with-fastai",
    "href": "01_Model/perceptnet.html#testing-with-fastai",
    "title": "Basic PerceptNet",
    "section": "Testing with FastAI",
    "text": "Testing with FastAI\n\nWe want to train the model using fastai, so we have to make sure that we can use it with the library.\n\n\nimport pandas as pd\n\nfrom fastai.vision.all import *\nfrom functools import partial\n\n\ndblock = DataBlock(blocks=(ImageBlock, ImageBlock, RegressionBlock),\n                   getters=[ColReader(2, pref=path_ref),\n                            ColReader(1, pref=path_dist),\n                            ColReader(0)],\n                   n_inp=2)\n\n\ndf = pd.read_csv(\"../tid2008.csv\", index_col=0)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      MOS\n      Dist\n      Ref\n    \n  \n  \n    \n      0\n      5.9706\n      I01_01_1.bmp\n      I01.BMP\n    \n    \n      1\n      5.4167\n      I01_01_2.bmp\n      I01.BMP\n    \n    \n      2\n      4.5556\n      I01_01_3.bmp\n      I01.BMP\n    \n    \n      3\n      4.3143\n      I01_01_4.bmp\n      I01.BMP\n    \n    \n      4\n      6.1429\n      I01_02_1.bmp\n      I01.BMP\n    \n  \n\n\n\n\n\ndls = dblock.dataloaders(df, bs=32)\n\n\nlearn = Learner(dls=dls,\n                model=PerceptNet(in_channels=3),\n                loss_func=loss_perceptnet_fn)\n\n\nlr = learn.lr_find()\n\n\n\n\n\n\n\n\nlr\n\nSuggestedLRs(valley=0.0014454397605732083)"
  }
]